# This file is versioned.
# Please copy and rename this config file to a private config.yaml

sim:  # simulations
  env:
    size: 20  # Size of the board
    number_coins: 60  # Number of coins on the board
    max_length: 100  # Maximum number of iterations before terminal state
  output:
    path: path/to/output/videos
    save_figs: No
    save_every: 100  # Save results every 100 episodes

  agent:
    type: curious  # in ["default", "curious"]

learning:
  cuda: Yes
  batch_size: 64
  num_episodes: 1000 # Number of episodes of learning

  DDQN: Yes
  gamma: 0.999 # Discount factor.
  EPS_START: 0.9 # Probability of exploration.
  EPS_END: 0.1
  EPS_DECAY: 1000
  lr: 0.01 # Learning rate
  update_frequency: 100 # Update the target net every...
  update_type: hard # Type of update.
  tau: 0.5

  curiosity:
    eta: 0.2
    feature_net:
      lr: 0.001
    feature_predictor:
      lr: 0.001
    action_predictor:
      lr: 0.001

testing:
  policy:
    random_action_prob: 0.1

experience_replay:
  size: 10000  # Size of the experience replay buffer

metrics:
  train_cycle_length: 20 # in number of episodes (metrics are averaged over)
  test_cycle_length: 20
