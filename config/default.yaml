# This file is versioned.
# Please copy and rename this config file to a private config.yaml

sim:  # simulations
  env:
    size: 20  # Size of the board
    number_coins: 60  # Number of coins on the board
    max_length: 100  # Maximum number of iterations before terminal state
    state:
      # Types of state:
      # - simple: 4 values for the 4 directions with the number of coins in each direction (-1 if wall)
      # - progressive: see everything with a radius of depth_of_field
      # - hard: see everything in every direction until the next wall
      # - memory: progressive bu seen positions stay in the state
      type: progressive  # in [progressive, hard, memory, simple] -- simple is 4 numbers giving the number of coins in the 4 directions
      depth_of_field: 5  # only if progressive state. Size of the viewing radius

  output:
    path: path/to/output/videos
    save_figs: Yes

  agent:
    curious: Yes  # Use ICM Module?
    step: ICM  # In RF, ICM and pixel

learning:
  cuda: No
  save_models: Yes
  load_model: No
  n_processes: 4
  num_episodes: 1000 # Number of episodes of learning

  gamma: 0.9 # Discount factor.

  lr: 0.0001 # Learning rate for the actor, or dqn
  update_frequency: 100 # Update the target net every...
  tau: 0.5  # When updating the target nets do tau * target + (1 - tau) * current

  gumbel_softmax:  # For the actor critic differentiable argmax
    use: Yes
    tau: 0.5

  value_loss_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 50
  gae:
    tau: 1.00

  icm:  # To learn the ICM Module.
    eta: 0.2
    beta: 0.2
    lbd: 0.1
    lr: 0.001
    feature_dim: 128  # Dimension of the feature space

metrics:
  train_cycle_length: 10 # in number of episodes (metrics are averaged over)
  test_cycle_length: 10
